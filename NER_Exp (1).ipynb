{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ry9Pa7dq_dZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "id": "XmAVeucbrcMz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").ffill()\n",
    "words = list(data[\"Word\"].unique())\n",
    "tags = list(data[\"Tag\"].unique())\n",
    "\n",
    "if \"ENDPAD\" not in words:\n",
    "    words.append(\"ENDPAD\")\n",
    "\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}"
   ],
   "metadata": {
    "id": "bE8VEjpnrc8C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data.head(50)"
   ],
   "metadata": {
    "id": "2DGpH3WzrmDi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essential info about tagged entities:\n",
    "```\n",
    "geo = Geographical Entity\n",
    "org = Organization\n",
    "per = Person\n",
    "gpe = Geopolitical Entity\n",
    "tim = Time indicator\n",
    "art = Artifact\n",
    "eve = Event\n",
    "nat = Natural Phenomenon\n",
    "```"
   ],
   "metadata": {
    "id": "b-xy1yJtIUdj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
    "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
   ],
   "metadata": {
    "id": "aOWkBoLXsPvD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Unique tags are:\", tags)"
   ],
   "metadata": {
    "id": "m6_c7uwHsa_q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Group words by sentences\n",
    "class SentenceGetter:\n",
    "    def __init__(self, data):\n",
    "        self.grouped = data.groupby(\"Sentence #\", group_keys=False).apply(\n",
    "            lambda s: [(w, t) for w, t in zip(s[\"Word\"], s[\"Tag\"])]\n",
    "        )\n",
    "        self.sentences = list(self.grouped)\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences\n"
   ],
   "metadata": {
    "id": "-Zo6uyoCsiEb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sentences[35]"
   ],
   "metadata": {
    "id": "Z-pZFuuAs4Xa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Encode sentences\n",
    "X = [[word2idx[w] for w, t in s] for s in sentences]\n",
    "y = [[tag2idx[t] for w, t in s] for s in sentences]"
   ],
   "metadata": {
    "id": "-3Yd8hqMssdK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "word2idx"
   ],
   "metadata": {
    "collapsed": true,
    "id": "ipTK2DOstD3j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": true,
    "id": "eWV-M4IftKUy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Pad sequences\n",
    "max_len = 50\n",
    "X_pad = pad_sequence([torch.tensor(seq) for seq in X], batch_first=True, padding_value=word2idx[\"ENDPAD\"])\n",
    "y_pad = pad_sequence([torch.tensor(seq) for seq in y], batch_first=True, padding_value=tag2idx[\"O\"])\n",
    "X_pad = X_pad[:, :max_len]\n",
    "y_pad = y_pad[:, :max_len]"
   ],
   "metadata": {
    "id": "m6hFevHstXKL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_pad[0]"
   ],
   "metadata": {
    "collapsed": true,
    "id": "TA2On7iAtzAK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pad[0]"
   ],
   "metadata": {
    "collapsed": true,
    "id": "8Cx7lJhft4aa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "id": "74HBxw81tap6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.X[idx],\n",
    "            \"labels\": self.y[idx]\n",
    "        }\n",
    "\n",
    "train_loader = DataLoader(NERDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(NERDataset(X_test, y_test), batch_size=32)\n"
   ],
   "metadata": {
    "id": "ukXTrKSPtipK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model definition\n",
    "class BiLSTMTagger(nn.Module):\n",
    "    # Include your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Include your code here\n",
    "\n",
    "\n",
    "\n",
    ""
   ],
   "metadata": {
    "id": "MFu8201Qtnl6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model =\n",
    "loss_fn =\n",
    "optimizer ="
   ],
   "metadata": {
    "id": "onjJJSuAuFyL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training and Evaluation Functions\n",
    "def train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3):\n",
    "    # Include the training and evaluation functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return train_losses, val_losses"
   ],
   "metadata": {
    "id": "xlcDlPEruRB6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_loader, X_test, y_test):\n",
    "    model.eval()\n",
    "    true_tags, pred_tags = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            for i in range(len(labels)):\n",
    "                for j in range(len(labels[i])):\n",
    "                    if labels[i][j] != tag2idx[\"O\"]:\n",
    "                        true_tags.append(idx2tag[labels[i][j].item()])\n",
    "                        pred_tags.append(idx2tag[preds[i][j].item()])\n"
   ],
   "metadata": {
    "id": "rALxE4gTuVUr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run training and evaluation\n",
    "train_losses, val_losses = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3)\n",
    "evaluate_model(model, test_loader, X_test, y_test)"
   ],
   "metadata": {
    "id": "AVJ5f5hyubC0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot loss\n",
    "# Name : Mohammed Saajid\n",
    "# Register Number : 212223240093\n",
    "history_df = pd.DataFrame({\"loss\": train_losses, \"val_loss\": val_losses})\n",
    "history_df.plot(title=\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "8HpgHVLhwPWE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inference and prediction\n",
    "i = 125\n",
    "model.eval()\n",
    "sample = X_test[i].unsqueeze(0).to(device)\n",
    "output = model(sample)\n",
    "preds = torch.argmax(output, dim=-1).squeeze().cpu().numpy()\n",
    "true = y_test[i].numpy()\n",
    "\n",
    "# Name : Mohammed Saajid\n",
    "# Register Number : 212223240093\n",
    "print(\"{:<15} {:<10} {}\\n{}\".format(\"Word\", \"True\", \"Pred\", \"-\" * 40))\n",
    "for w_id, true_tag, pred_tag in zip(X_test[i], y_test[i], preds):\n",
    "    if w_id.item() != word2idx[\"ENDPAD\"]:\n",
    "        word = words[w_id.item() - 1]\n",
    "        true_label = tags[true_tag.item()]\n",
    "        pred_label = tags[pred_tag]\n",
    "        print(f\"{word:<15} {true_label:<10} {pred_label}\")"
   ],
   "metadata": {
    "id": "C7YGTaIPwQEY"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}